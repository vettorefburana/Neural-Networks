{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.utils import plot_model\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import math\n",
    "import random\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import eli5\n",
    "from eli5.sklearn import PermutationImportance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def regression_nn_loss(sigma_sq, epsilon = 1e-6):\n",
    "    def nn_loss(y_true, y_pred):\n",
    "        return 0.5 * keras.backend.mean(keras.backend.log(sigma_sq + epsilon) + keras.backend.square(y_true - y_pred) / (sigma_sq + epsilon))\n",
    "\n",
    "    return nn_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate dataset\n",
    "n = 10 # number of features\n",
    "k = 50 # number of samples\n",
    "x = 0\n",
    "np.random.seed(100)\n",
    "numbers_list = np.array( random.sample(range(100), k) )\n",
    "while x < n:\n",
    "    numbers_list = np.vstack((numbers_list, np.array( random.sample(range(100), k) )))\n",
    "    x = x + 1\n",
    "\n",
    "dataset = numbers_list.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize the dataset\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "dataset = scaler.fit_transform(dataset)\n",
    "Y = dataset[:, 0].astype(\"float32\")\n",
    "X = dataset[:, 1:].astype(\"float32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_tot = int( X.shape[1] )\n",
    "splits = int( 2 )\n",
    "n_splits = int( n_tot/splits )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.random.seed(100)\n",
    "#dataset = np.random.randn(500, 11)\n",
    "#X = dataset[:,0:10].astype(\"float32\")\n",
    "#Y = dataset[:,10].astype(\"float32\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Network 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# solution 1 -- split single neurons\n",
    "\n",
    "input = keras.layers.Input(shape = (n_tot), name = \"input\")\n",
    "layer1 = keras.layers.Lambda(lambda x: x[:,0:n_splits], name = \"split_1\")(input)# take the first n_splits neurons\n",
    "layer2 = keras.layers.Lambda(lambda x: x[:,n_splits:], name = \"split_2\")(input) # take the other neurons\n",
    "output1 = keras.layers.Dense(units = 1, activation = \"linear\", name = \"dense_1\")(layer1)# add extra dense layer\n",
    "output2 = keras.layers.Dense(units = 1, activation = \"linear\", name = \"dense_2\")(layer2)# add extra dense layer\n",
    "output = keras.layers.average([output1, output2], name = \"output\") # average the layers to get a single output layer\n",
    "\n",
    "model = keras.models.Model(input, output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print( model.summary() )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model(model, show_shapes=True, show_layer_names=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit and forecast \n",
    "model.compile(loss = 'mean_squared_error', optimizer = 'adam')\n",
    "history = model.fit(X, Y, epochs=100)\n",
    "forecast = model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot MSE\n",
    "plt.plot(history.history[\"loss\"])\n",
    "plt.title('MSE')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Network 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# solution 2 -- split entire dataset\n",
    "\n",
    "input = keras.layers.Input(shape=(n_tot), name = \"input\")\n",
    "split = keras.layers.Lambda(lambda x: tf.split(x,num_or_size_splits = splits,axis = 1), name = \"split\")(input) # split dataset in half\n",
    "layer1 = keras.layers.Dense(units = 1, activation = \"linear\", name = \"dense_1\")(split[0])\n",
    "layer2 = keras.layers.Dense(units = 1, activation = \"linear\", name = \"dense_2\")(split[1])\n",
    "output = keras.layers.concatenate([layer1, layer2], name = \"output\") # produces a different output for each subset\n",
    "\n",
    "model = keras.models.Model(input, output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print( model.summary() )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model(model, show_shapes=True, show_layer_names=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit and forecast \n",
    "model.compile(loss = 'mean_squared_error', optimizer = 'adam')\n",
    "history = model.fit(X, Y, epochs=100)\n",
    "forecast = model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot MSE\n",
    "plt.plot(history.history[\"loss\"])\n",
    "plt.title('MSE')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Network 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# solution 3 -- separate inputs \n",
    "input_1 = keras.layers.Input(shape=(n_splits,), name = \"input_1\")\n",
    "input_2 = keras.layers.Input(shape=(n_splits,), name = \"input_2\")\n",
    "layer_1 = keras.layers.Dense(units = 1, activation = \"linear\", name = \"dense_1\")(input_1)\n",
    "layer_2 = keras.layers.Dense(units = 1, activation = \"linear\", name = \"dense_2\")(input_2)\n",
    "output = keras.layers.Add(name = \"output\")([layer_1, layer_2])\n",
    "\n",
    "model = keras.models.Model(inputs=[input_1,input_2], outputs=output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print( model.summary() )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model(model, show_shapes=True, show_layer_names=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit and forecast \n",
    "model.compile(loss = 'mean_squared_error', optimizer = 'adam')\n",
    "XX = (X[:, :n_splits], X[:, n_splits:])\n",
    "history = model.fit(XX, Y, epochs=100)\n",
    "forecast = model.predict(XX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot MSE\n",
    "plt.plot(history.history[\"loss\"])\n",
    "plt.title('MSE')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confidence interval for network 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.framework.ops import disable_eager_execution\n",
    "disable_eager_execution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# confidence interval \n",
    "input = keras.layers.Input(shape = (n_tot), name = \"input\")\n",
    "layer1 = keras.layers.Lambda(lambda x: x[:,0:n_splits], name = \"split_1\")(input)  \n",
    "layer2 = keras.layers.Lambda(lambda x: x[:,n_splits:], name = \"split_2\")(input)   \n",
    "output1 = keras.layers.Dense(units = 1, activation = \"linear\", name = \"dense_1\")(layer1)                 \n",
    "output2 = keras.layers.Dense(units = 1, activation = \"linear\", name = \"dense_2\")(layer2)                 \n",
    "output = keras.layers.average([output1, output2], name = \"output\")           \n",
    "mean = keras.layers.Dense(units = 1, activation = \"linear\", name = \"mean\")(output) # add layer for the mean\n",
    "var = keras.layers.Dense(units = 1, activation = \"softplus\", name = \"variance\")(output) # add layer for the variance\n",
    "\n",
    "train_model = keras.models.Model(input, mean)\n",
    "pred_model = keras.models.Model(input, [mean, var])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pred_model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model(pred_model, show_shapes=True, show_layer_names=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_model.compile(loss=regression_nn_loss(var), optimizer=\"adam\", metrics=['MeanSquaredError'])\n",
    "history = train_model.fit(X, Y, epochs = 100)\n",
    "mean, var = pred_model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot MSE\n",
    "plt.plot(history.history[\"MeanSquaredError\"])\n",
    "plt.title('MSE')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot confidence interval\n",
    "li = mean - 1.96*var\n",
    "ui = mean + 1.96*var\n",
    "fin = np.concatenate((li, mean, ui), axis = 1)\n",
    "plt.plot(fin)\n",
    "plt.title('Forecast')\n",
    "plt.xlabel('steps ahead')\n",
    "#plt.legend([\"li\",'mean', \"ui\"], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature importance\n",
    "perm = PermutationImportance(train_model, scoring = 'neg_mean_squared_error', random_state = 1).fit(X, Y)\n",
    "eli5.show_weights(perm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
